{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Schema: Integration Quickbook\n",
    "\n",
    "This notebook demonstrates various integration scenarios and use cases for the `smart-schema` library. We'll show how to leverage `smart-schema` for generating Pydantic models and validating data in common workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's ensure `smart-schema` is installed and import necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vw/93nznt8545n9l6pq4r8x50680000gn/T/ipykernel_70380/2697095934.py:6: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# Ensure you have smart-schema installed\n",
    "# !pip install ../\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pydantic import BaseModel, ValidationError\n",
    "from typing import List, Dict, Optional, Any\n",
    "from datetime import datetime\n",
    "\n",
    "from smart_schema import ModelGenerator, ModelValidator\n",
    "from smart_schema.core.model_utils import save_model_to_file, load_and_validate_json_as_model\n",
    "\n",
    "# For OpenAI based generation (optional, ensure OPENAI_API_KEY is set in your environment)\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"API_KEY\" \n",
    "\n",
    "MODELS_DIR = Path(\"generated_integration_models\")\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "DATA_DIR = Path(\"integration_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case 1: CSV Data Ingestion Pipeline\n",
    "\n",
    "Scenario: You receive daily sales data as CSV files. Before loading this data into your database or analytics platform, you need to validate its structure and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Sales Data:\n",
      "         Date ProductID     ProductName     Category  QuantitySold  UnitPrice  \\\n",
      "0  2024-07-01      P001      Laptop Pro  Electronics          10.0     1200.0   \n",
      "1  2024-07-01      P002  Wireless Mouse  Accessories          50.0       25.0   \n",
      "2  2024-07-01      P003    Office Chair    Furniture           5.0      150.0   \n",
      "3  2024-07-02      P001      Laptop Pro  Electronics           8.0     1200.0   \n",
      "4  2024-07-02      P004        Keyboard  Accessories          30.0       75.0   \n",
      "\n",
      "   TotalPrice Region  \n",
      "0     12000.0  North  \n",
      "1      1250.0  North  \n",
      "2       750.0   West  \n",
      "3      9600.0  South  \n",
      "4      2250.0   East  \n"
     ]
    }
   ],
   "source": [
    "csv_file_path = DATA_DIR / \"sales_records.csv\"\n",
    "sales_df = pd.read_csv(csv_file_path)\n",
    "print(\"Sample Sales Data:\")\n",
    "print(sales_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.1: Generate a Pydantic Model from the CSV\n",
    "\n",
    "We can use `ModelGenerator` to infer a schema from the CSV data. For fields like `Date`, we can provide hints for datetime parsing. We'll use the `smart_inference=True` for more robust type detection if an OpenAI key is available, otherwise, it will fall back to basic inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully generated SalesRecordModel using smart inference.\n",
      "SalesRecordModel Schema:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'properties': {'Date': {'description': 'The date of the sale in ISO format.',\n",
       "   'format': 'date-time',\n",
       "   'title': 'Date',\n",
       "   'type': 'string'},\n",
       "  'ProductID': {'description': 'The unique identifier for the product.',\n",
       "   'title': 'Productid',\n",
       "   'type': 'string'},\n",
       "  'ProductName': {'description': 'The name of the product sold.',\n",
       "   'title': 'Productname',\n",
       "   'type': 'string'},\n",
       "  'Category': {'description': 'The category to which the product belongs.',\n",
       "   'title': 'Category',\n",
       "   'type': 'string'},\n",
       "  'QuantitySold': {'description': 'The quantity of the product sold.',\n",
       "   'title': 'Quantitysold',\n",
       "   'type': 'number'},\n",
       "  'UnitPrice': {'description': 'The price per unit of the product.',\n",
       "   'title': 'Unitprice',\n",
       "   'type': 'number'},\n",
       "  'TotalPrice': {'description': 'The total price for the quantity sold.',\n",
       "   'title': 'Totalprice',\n",
       "   'type': 'number'},\n",
       "  'Region': {'description': 'The geographical region where the sale was made.',\n",
       "   'title': 'Region',\n",
       "   'type': 'string'}},\n",
       " 'required': ['Date',\n",
       "  'ProductID',\n",
       "  'ProductName',\n",
       "  'Category',\n",
       "  'QuantitySold',\n",
       "  'UnitPrice',\n",
       "  'TotalPrice',\n",
       "  'Region'],\n",
       " 'title': 'SalesRecord',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_model_generator = ModelGenerator(name=\"SalesRecord\", smart_inference=True) # Set to False if no OpenAI key\n",
    "\n",
    "try:\n",
    "    # Attempt smart inference first\n",
    "    SalesRecordModel = sales_model_generator.from_dataframe(\n",
    "        sales_df, \n",
    "        datetime_columns=[\"Date\"]\n",
    "    )\n",
    "    print(\"Successfully generated SalesRecordModel using smart inference.\")\n",
    "except ValueError as e:\n",
    "    print(f\"Smart inference failed (likely missing API key or invalid config): {e}\")\n",
    "    print(\"Falling back to basic inference.\")\n",
    "    sales_model_generator_basic = ModelGenerator(name=\"SalesRecord\", smart_inference=False)\n",
    "    SalesRecordModel = sales_model_generator_basic.from_dataframe(\n",
    "        sales_df, \n",
    "        datetime_columns=[\"Date\"]\n",
    "    )\n",
    "    print(\"Successfully generated SalesRecordModel using basic inference.\")\n",
    "\n",
    "# Display the generated model schema\n",
    "print(\"SalesRecordModel Schema:\")\n",
    "SalesRecordModel.model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.2: Save the Generated Model (Optional but Recommended)\n",
    "\n",
    "Saving the model to a Python file allows you to reuse it without regenerating it every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SalesRecordModel saved to generated_integration_models/sales_record_model.py\n"
     ]
    }
   ],
   "source": [
    "# Use the imported utility from smart_schema.core.model_utils\n",
    "sales_model_file_path = MODELS_DIR / \"sales_record_model.py\"\n",
    "\n",
    "save_model_to_file(SalesRecordModel, output_path=str(sales_model_file_path), model_name=\"SalesRecord\")\n",
    "print(f\"SalesRecordModel saved to {sales_model_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.3: Validate the CSV Data\n",
    "\n",
    "Now, use `ModelValidator` to validate the DataFrame against the generated `SalesRecordModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of valid sales records: 12\n",
      "Number of invalid sales records: 0\n"
     ]
    }
   ],
   "source": [
    "sales_validator = ModelValidator(SalesRecordModel)\n",
    "valid_records_df, invalid_records_list = sales_validator.validate_dataframe(sales_df)\n",
    "\n",
    "print(f\"Number of valid sales records: {len(valid_records_df)}\")\n",
    "print(f\"Number of invalid sales records: {len(invalid_records_list)}\")\n",
    "\n",
    "if invalid_records_list:\n",
    "    print(\"Invalid Sales Records Details:\")\n",
    "    for record in invalid_records_list[:3]: # Print details for the first 3 invalid records\n",
    "        print(f\"Record Index: {record['index']}\")\n",
    "        print(f\"Data: {record['record']}\")\n",
    "        print(f\"Errors: {record['errors']}\")\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demonstrates a typical data ingestion validation step. You could then proceed to load `valid_records_df` into your system and log/handle `invalid_records_list` for review or correction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case 2: API Request/Response Validation\n",
    "\n",
    "Scenario: You are developing or integrating with an API. `smart-schema` can help define and enforce data contracts for API requests and responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1: Define Schema from API Documentation or Example JSON\n",
    "\n",
    "Imagine you have an example JSON request body for creating a product in an e-commerce system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Product API Request:\n",
      "{\n",
      "  \"product_id\": \"P008\",\n",
      "  \"name\": \"Gaming Keyboard RGB\",\n",
      "  \"category\": \"Electronics\",\n",
      "  \"price\": 129.99,\n",
      "  \"stock\": 50,\n",
      "  \"description\": \"Mechanical gaming keyboard with customizable RGB lighting.\",\n",
      "  \"specifications\": {\n",
      "    \"switch_type\": \"Blue\",\n",
      "    \"layout\": \"Full-size\",\n",
      "    \"connectivity\": [\n",
      "      \"USB-C\",\n",
      "      \"Bluetooth\"\n",
      "    ]\n",
      "  },\n",
      "  \"supplier_info\": {\n",
      "    \"supplier_id\": \"SUPP-003\",\n",
      "    \"name\": \"TechGear Inc.\"\n",
      "  },\n",
      "  \"is_active\": true,\n",
      "  \"tags\": [\n",
      "    \"gaming\",\n",
      "    \"keyboard\",\n",
      "    \"rgb\",\n",
      "    \"mechanical\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "api_request_path = DATA_DIR / \"product_api_request.json\"\n",
    "with open(api_request_path, 'r') as f:\n",
    "    product_api_example = json.load(f)\n",
    "\n",
    "print(\"Sample Product API Request:\")\n",
    "print(json.dumps(product_api_example, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully generated ProductCreateRequestModel using smart inference.\n",
      "ProductCreateRequestModel Schema:\n"
     ]
    }
   ],
   "source": [
    "product_api_model_generator = ModelGenerator(name=\"ProductCreateRequest\", smart_inference=True) # Set to False if no OpenAI key\n",
    "\n",
    "try:\n",
    "    ProductCreateRequestModel = product_api_model_generator.from_json(product_api_example)\n",
    "    print(\"Successfully generated ProductCreateRequestModel using smart inference.\")\n",
    "except ValueError as e: # Catching broader errors as from_json with OpenAI might have specific error types\n",
    "    print(f\"Smart inference failed: {e}\")\n",
    "    print(\"Falling back to basic inference.\")\n",
    "    product_api_model_generator_basic = ModelGenerator(name=\"ProductCreateRequest\", smart_inference=False)\n",
    "    ProductCreateRequestModel = product_api_model_generator_basic.from_json(product_api_example)\n",
    "    print(\"Successfully generated ProductCreateRequestModel using basic inference.\")\n",
    "\n",
    "print(\"ProductCreateRequestModel Schema:\")\n",
    "ProductCreateRequestModel.model_json_schema()\n",
    "\n",
    "products_model_file_path = MODELS_DIR / \"product_create_request_model.py\"\n",
    "save_model_to_file(ProductCreateRequestModel, output_path=str(products_model_file_path), model_name=\"ProductCreateRequest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: Validate an Incoming API Request\n",
    "\n",
    "In your API endpoint (e.g., using FastAPI or Flask), you would parse the incoming JSON and validate it using the generated model. We will use `ModelValidator` for this.\n",
    "\n",
    "**Note:** The `ProductCreateRequestModel` was generated based on the single example in `product_api_request.json`. If our `valid_request_data` below differs in structure (e.g., missing fields like `specifications.switch_type` which were present in the generation example), it might initially fail validation. This demonstrates how the generated model enforces the schema derived from the example. We've adjusted `valid_request_data` to include these fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Validating a Correct Request (now adjusted) ---\n",
      "Request is valid! Product: Smart Watch Series X\n",
      "\n",
      "--- Validating an Incorrect Request ---\n",
      "Request is invalid!\n",
      "[{'type': 'missing', 'loc': ('category',), 'msg': 'Field required', 'input': {'product_id': 'P010', 'name': 'Budget Tablet', 'price': 'ninety-nine', 'stock': -10, 'description': 'Affordable tablet for basic use.', 'specifications': {'screen_size': '10 inch', 'ram': '4GB'}, 'is_active': 'yes'}, 'url': 'https://errors.pydantic.dev/2.6/v/missing'}, {'type': 'float_parsing', 'loc': ('price',), 'msg': 'Input should be a valid number, unable to parse string as a number', 'input': 'ninety-nine', 'url': 'https://errors.pydantic.dev/2.6/v/float_parsing'}, {'type': 'missing', 'loc': ('specifications', 'switch_type'), 'msg': 'Field required', 'input': {'screen_size': '10 inch', 'ram': '4GB'}, 'url': 'https://errors.pydantic.dev/2.6/v/missing'}, {'type': 'missing', 'loc': ('specifications', 'layout'), 'msg': 'Field required', 'input': {'screen_size': '10 inch', 'ram': '4GB'}, 'url': 'https://errors.pydantic.dev/2.6/v/missing'}, {'type': 'missing', 'loc': ('specifications', 'connectivity'), 'msg': 'Field required', 'input': {'screen_size': '10 inch', 'ram': '4GB'}, 'url': 'https://errors.pydantic.dev/2.6/v/missing'}, {'type': 'missing', 'loc': ('supplier_info',), 'msg': 'Field required', 'input': {'product_id': 'P010', 'name': 'Budget Tablet', 'price': 'ninety-nine', 'stock': -10, 'description': 'Affordable tablet for basic use.', 'specifications': {'screen_size': '10 inch', 'ram': '4GB'}, 'is_active': 'yes'}, 'url': 'https://errors.pydantic.dev/2.6/v/missing'}, {'type': 'missing', 'loc': ('tags',), 'msg': 'Field required', 'input': {'product_id': 'P010', 'name': 'Budget Tablet', 'price': 'ninety-nine', 'stock': -10, 'description': 'Affordable tablet for basic use.', 'specifications': {'screen_size': '10 inch', 'ram': '4GB'}, 'is_active': 'yes'}, 'url': 'https://errors.pydantic.dev/2.6/v/missing'}]\n"
     ]
    }
   ],
   "source": [
    "# Simulate an incoming valid request\n",
    "# MODIFIED: Added switch_type and layout to conform to the schema generated from product_api_request.json\n",
    "# For a smartwatch, these might be \"N/A\" or similar if the fields are required strings.\n",
    "# If the schema allowed Optional types for these, None would be appropriate.\n",
    "valid_request_data = {\n",
    "  \"product_id\": \"P009\",\n",
    "  \"name\": \"Smart Watch Series X\",\n",
    "  \"category\": \"Wearables\",\n",
    "  \"price\": 299.99,\n",
    "  \"stock\": 150,\n",
    "  \"description\": \"Latest smart watch with advanced health tracking.\",\n",
    "  \"specifications\": {\n",
    "    \"switch_type\": \"N/A\",  # Added to match schema from example\n",
    "    \"layout\": \"N/A\",     # Added to match schema from example\n",
    "    \"display_type\": \"AMOLED\", # This field is extraneous based on original example but Pydantic allows extra by default\n",
    "    \"water_resistance\": \"5ATM\",# This field is extraneous based on original example\n",
    "    \"connectivity\": [\"Bluetooth 5.2\", \"NFC\"] # This was in the original example, but for a keyboard\n",
    "  },\n",
    "  \"supplier_info\": {\n",
    "    \"supplier_id\": \"SUPP-001\",\n",
    "    \"name\": \"ElectroGadgets Ltd.\"\n",
    "  },\n",
    "  \"is_active\": True,\n",
    "  \"tags\": [\"smartwatch\", \"health\", \"wearable\"]\n",
    "}\n",
    "\n",
    "# Simulate an incoming invalid request (e.g., missing required field, wrong type)\n",
    "# This request is missing 'category', 'supplier_info', 'tags' which are top-level required fields\n",
    "# and 'specifications' is missing 'connectivity' and has different fields than the example.\n",
    "invalid_request_data = {\n",
    "  \"product_id\": \"P010\",\n",
    "  \"name\": \"Budget Tablet\",\n",
    "  # 'category' is missing\n",
    "  \"price\": \"ninety-nine\", # Wrong type\n",
    "  \"stock\": -10, # Invalid value \n",
    "  \"description\": \"Affordable tablet for basic use.\",\n",
    "  \"specifications\": { \n",
    "      # \"switch_type\": \"Membrane\", # If we add these, other errors would remain\n",
    "      # \"layout\": \"Compact\",\n",
    "      \"screen_size\": \"10 inch\", # Extraneous based on original example\n",
    "      \"ram\": \"4GB\"              # Extraneous based on original example\n",
    "      # \"connectivity\" is missing, which was in the example.\n",
    "  },\n",
    "  \"is_active\": \"yes\" # Wrong type\n",
    "  # supplier_info is missing\n",
    "  # tags is missing\n",
    "}\n",
    "\n",
    "# Create a validator instance for the Product API model\n",
    "product_api_validator = ModelValidator(ProductCreateRequestModel)\n",
    "\n",
    "print(\"--- Validating a Correct Request (now adjusted) ---\")\n",
    "is_valid, errors = product_api_validator.validate_record(valid_request_data)\n",
    "if is_valid:\n",
    "    validated_model = ProductCreateRequestModel(**valid_request_data) \n",
    "    print(f\"Request is valid! Product: {validated_model.name}\")\n",
    "    # print(validated_model.model_dump_json(indent=2)) # Optional: view the validated data\n",
    "else:\n",
    "    print(f\"Request is invalid!\")\n",
    "    print(errors)\n",
    "\n",
    "print(\"\\n--- Validating an Incorrect Request ---\")\n",
    "is_valid, errors = product_api_validator.validate_record(invalid_request_data)\n",
    "if is_valid:\n",
    "    # This case should ideally not be reached for invalid_request_data\n",
    "    print(f\"Request is valid (but was expected to be invalid)!\") \n",
    "else:\n",
    "    print(f\"Request is invalid!\")\n",
    "    print(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This illustrates how you'd integrate `smart-schema` into an API's request handling logic to ensure data integrity. The same principle applies to validating API responses before sending them out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case 3: Configuration File Management\n",
    "\n",
    "Scenario: Your application relies on a JSON configuration file. `smart-schema` can validate this configuration on startup to catch errors early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Application Configuration:\n",
      "{\n",
      "  \"application_name\": \"SmartApp\",\n",
      "  \"version\": \"1.2.3\",\n",
      "  \"debug_mode\": true,\n",
      "  \"server_settings\": {\n",
      "    \"host\": \"localhost\",\n",
      "    \"port\": 8080,\n",
      "    \"timeout_seconds\": 30\n",
      "  },\n",
      "  \"database_connection\": {\n",
      "    \"type\": \"postgresql\",\n",
      "    \"host\": \"db.example.com\",\n",
      "    \"port\": 5432,\n",
      "    \"username\": \"admin_user\",\n",
      "    \"password_env_var\": \"DB_PASSWORD\",\n",
      "    \"database_name\": \"app_data\",\n",
      "    \"connection_options\": {\n",
      "      \"ssl_mode\": \"require\",\n",
      "      \"max_connections\": 100\n",
      "    }\n",
      "  },\n",
      "  \"feature_flags\": {\n",
      "    \"new_dashboard\": true,\n",
      "    \"beta_user_access\": false,\n",
      "    \"enable_analytics\": true\n",
      "  },\n",
      "  \"logging\": {\n",
      "    \"level\": \"INFO\",\n",
      "    \"format\": \"%(asctime)s - %(levelname)s - %(message)s\",\n",
      "    \"file_path\": \"/var/log/smart_app.log\"\n",
      "  },\n",
      "  \"api_keys\": {\n",
      "    \"payment_gateway\": \"env:PAYMENT_API_KEY\",\n",
      "    \"geocoding_service\": \"env:GEO_API_KEY\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "config_file_path = DATA_DIR / \"app_config.json\"\n",
    "with open(config_file_path, 'r') as f:\n",
    "    app_config_example = json.load(f)\n",
    "\n",
    "print(\"Sample Application Configuration:\")\n",
    "print(json.dumps(app_config_example, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully generated AppConfigModel using smart inference.\n",
      "AppConfigModel Schema:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'$defs': {'ApiKeys': {'properties': {'payment_gateway': {'default': None,\n",
       "     'title': 'Payment Gateway',\n",
       "     'type': 'string'},\n",
       "    'geocoding_service': {'default': None,\n",
       "     'title': 'Geocoding Service',\n",
       "     'type': 'string'}},\n",
       "   'title': 'ApiKeys',\n",
       "   'type': 'object'},\n",
       "  'ConnectionOptions': {'properties': {'ssl_mode': {'default': None,\n",
       "     'title': 'Ssl Mode',\n",
       "     'type': 'string'},\n",
       "    'max_connections': {'default': None,\n",
       "     'title': 'Max Connections',\n",
       "     'type': 'integer'}},\n",
       "   'title': 'ConnectionOptions',\n",
       "   'type': 'object'},\n",
       "  'DatabaseConnection': {'properties': {'type': {'default': None,\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'host': {'default': None, 'title': 'Host', 'type': 'string'},\n",
       "    'port': {'default': None, 'title': 'Port', 'type': 'integer'},\n",
       "    'username': {'default': None, 'title': 'Username', 'type': 'string'},\n",
       "    'password_env_var': {'default': None,\n",
       "     'title': 'Password Env Var',\n",
       "     'type': 'string'},\n",
       "    'database_name': {'default': None,\n",
       "     'title': 'Database Name',\n",
       "     'type': 'string'},\n",
       "    'connection_options': {'allOf': [{'$ref': '#/$defs/ConnectionOptions'}],\n",
       "     'default': None}},\n",
       "   'title': 'DatabaseConnection',\n",
       "   'type': 'object'},\n",
       "  'FeatureFlags': {'properties': {'new_dashboard': {'default': None,\n",
       "     'title': 'New Dashboard',\n",
       "     'type': 'boolean'},\n",
       "    'beta_user_access': {'default': None,\n",
       "     'title': 'Beta User Access',\n",
       "     'type': 'boolean'},\n",
       "    'enable_analytics': {'default': None,\n",
       "     'title': 'Enable Analytics',\n",
       "     'type': 'boolean'}},\n",
       "   'title': 'FeatureFlags',\n",
       "   'type': 'object'},\n",
       "  'Logging': {'properties': {'level': {'default': None,\n",
       "     'title': 'Level',\n",
       "     'type': 'string'},\n",
       "    'format': {'default': None, 'title': 'Format', 'type': 'string'},\n",
       "    'file_path': {'default': None, 'title': 'File Path', 'type': 'string'}},\n",
       "   'title': 'Logging',\n",
       "   'type': 'object'},\n",
       "  'ServerSettings': {'properties': {'host': {'default': None,\n",
       "     'title': 'Host',\n",
       "     'type': 'string'},\n",
       "    'port': {'default': None, 'title': 'Port', 'type': 'integer'},\n",
       "    'timeout_seconds': {'default': None,\n",
       "     'title': 'Timeout Seconds',\n",
       "     'type': 'integer'}},\n",
       "   'title': 'ServerSettings',\n",
       "   'type': 'object'}},\n",
       " 'properties': {'application_name': {'default': None,\n",
       "   'title': 'Application Name',\n",
       "   'type': 'string'},\n",
       "  'version': {'default': None, 'title': 'Version', 'type': 'string'},\n",
       "  'debug_mode': {'default': None, 'title': 'Debug Mode', 'type': 'boolean'},\n",
       "  'server_settings': {'allOf': [{'$ref': '#/$defs/ServerSettings'}],\n",
       "   'default': None},\n",
       "  'database_connection': {'allOf': [{'$ref': '#/$defs/DatabaseConnection'}],\n",
       "   'default': None},\n",
       "  'feature_flags': {'allOf': [{'$ref': '#/$defs/FeatureFlags'}],\n",
       "   'default': None},\n",
       "  'logging': {'allOf': [{'$ref': '#/$defs/Logging'}], 'default': None},\n",
       "  'api_keys': {'allOf': [{'$ref': '#/$defs/ApiKeys'}], 'default': None}},\n",
       " 'title': 'Appconfig',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_config_model_generator = ModelGenerator(name=\"AppConfig\", smart_inference=False) # Set to False if no OpenAI key\n",
    "\n",
    "try:\n",
    "    AppConfigModel = app_config_model_generator.from_json(app_config_example)\n",
    "    print(\"Successfully generated AppConfigModel using smart inference.\")\n",
    "except ValueError as e:\n",
    "    print(f\"Smart inference failed: {e}\")\n",
    "    print(\"Falling back to basic inference.\")\n",
    "    app_config_model_generator_basic = ModelGenerator(name=\"AppConfig\", smart_inference=False)\n",
    "    AppConfigModel = app_config_model_generator_basic.from_json(app_config_example)\n",
    "    print(\"Successfully generated AppConfigModel using basic inference.\")\n",
    "\n",
    "print(\"AppConfigModel Schema:\")\n",
    "AppConfigModel.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_config_model_file_path = MODELS_DIR / \"app_config_model.py\"\n",
    "save_model_to_file(AppConfigModel, output_path=str(app_config_model_file_path), model_name=\"AppConfig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2: Load and Validate Configuration\n",
    "\n",
    "On application startup, you would load the JSON config file and validate it against the `AppConfigModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and Validating Correct Configuration ---\n",
      "Configuration for 'SmartApp' loaded and validated successfully by the utility.\n",
      "DB Host: db.example.com\n",
      "\n",
      "--- Loading and Validating Incorrect Configuration ---\n",
      "Error: Configuration validation failed for integration_data/app_config_invalid.json\n",
      "Validation of incorrect config failed as expected (see errors above from the utility).\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Loading and Validating Correct Configuration ---\")\n",
    "# Using the new utility from smart_schema\n",
    "config = load_and_validate_json_as_model(config_file_path, AppConfigModel) # Ensure config_file_path is defined from previous cell\n",
    "\n",
    "if config:\n",
    "    # The function already prints basic errors, we can add a success confirmation here\n",
    "    print(f\"Configuration for '{config.application_name}' loaded and validated successfully by the utility.\")\n",
    "    if hasattr(config, 'database_connection') and config.database_connection:\n",
    "         print(f\"DB Host: {config.database_connection.host}\")\n",
    "    else:\n",
    "         print(\"DB Host: Not available (database_connection might be missing or None in the config)\")\n",
    "else:\n",
    "    print(\"Loading/validation of correct configuration failed (see errors above from the utility).\")\n",
    "\n",
    "\n",
    "# Create a temporary invalid config file for demonstration\n",
    "invalid_config_path = DATA_DIR / \"app_config_invalid.json\"\n",
    "invalid_config_data = app_config_example.copy() # Ensure app_config_example is defined from previous cell\n",
    "invalid_config_data[\"server_settings\"][\"port\"] = \"not-a-port\" # Invalid type\n",
    "\n",
    "# Ensure 'database_connection' is handled correctly for creating the invalid example\n",
    "if \"database_connection\" in invalid_config_data:\n",
    "    del invalid_config_data[\"database_connection\"] \n",
    "    \n",
    "with open(invalid_config_path, 'w') as f:\n",
    "    json.dump(invalid_config_data, f, indent=2)\n",
    "\n",
    "print(\"\\n--- Loading and Validating Incorrect Configuration ---\")\n",
    "# The function will print error messages internally\n",
    "invalid_config_result = load_and_validate_json_as_model(invalid_config_path, AppConfigModel)\n",
    "\n",
    "if invalid_config_result is None:\n",
    "    print(\"Validation of incorrect config failed as expected (see errors above from the utility).\")\n",
    "else:\n",
    "    print(\"Incorrect config was unexpectedly validated by the utility.\")\n",
    "\n",
    "\n",
    "# Clean up temporary invalid config\n",
    "if invalid_config_path.exists(): # Check if file exists before trying to unlink\n",
    "   invalid_config_path.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ensures your application starts with a valid configuration, preventing runtime errors due to misconfigured settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This quickbook has demonstrated several practical use cases for `smart-schema`:\n",
    "\n",
    "1.  **Validating CSV data** during ingestion pipelines.\n",
    "2.  **Enforcing data contracts** for API requests (and responses).\n",
    "3.  **Validating application configuration files** on startup.\n",
    "\n",
    "`smart-schema` simplifies the process of creating Pydantic models from various data sources, enabling robust data validation across different parts of your applications and workflows. The smart inference capabilities (powered by OpenAI when available) further streamline model generation, especially for complex and nested data structures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
